{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1hX89gipdLkeipYCJxJJhGGXoizAA6xhz",
      "authorship_tag": "ABX9TyOfbtL06GdUAwaCaKGyJpXr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JiwooNAM/Jacxxy/blob/main/Neuropixel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umtUIIM0QumW",
        "outputId": "85dbac5e-8f72-4489-e41c-69cf333006d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Torch: 2.8.0+cu126 | CUDA: True\n"
          ]
        }
      ],
      "source": [
        "!pip -q install pynwb h5py matplotlib\n",
        "# 파이토치는 Colab에 기본 설치되어 있습니다. (torch==2.x)\n",
        "import torch, sys\n",
        "print(\"Torch:\", torch.__version__, \"| CUDA:\", torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 예: 드라이브에 업로드한 NWB 파일 경로\n",
        "session_files = [\n",
        "    \"/content/drive/MyDrive/Neuropixel/sub-619293_ses-1184980079_ogen.nwb\",\n",
        "    \"/content/drive/MyDrive/Neuropixel/sub-619296_ses-1187930705_ogen.nwb\",\n",
        "]"
      ],
      "metadata": {
        "id": "H2pbS9fERL07",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf3ff3f7-7fad-48db-d83f-3b2b1b7687be"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import copy\n",
        "import math\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Optional: NWB loading\n",
        "try:\n",
        "    from pynwb import NWBHDF5IO\n",
        "    HAS_NWB = True\n",
        "except Exception:\n",
        "    HAS_NWB = False"
      ],
      "metadata": {
        "id": "_W6Pa7vwT7je"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# =============================\n",
        "# 1) Data I/O: NWB → binned spikes\n",
        "# =============================\n"
      ],
      "metadata": {
        "id": "frVep2sGTiN6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_spikes_from_nwb(path):\n",
        "    \"\"\"Return dict: {unit_id(int): spike_times(np.ndarray, seconds)}\"\"\"\n",
        "    assert HAS_NWB, \"pynwb not installed. Install pynwb or provide spikes directly.\"\n",
        "    io = NWBHDF5IO(path, 'r')\n",
        "    nwbfile = io.read()\n",
        "    spike_dict = {}\n",
        "    for i, unit_id in enumerate(nwbfile.units.id[:]):\n",
        "        spike_dict[int(unit_id)] = np.asarray(nwbfile.units['spike_times'][i])\n",
        "    io.close()\n",
        "    return spike_dict\n",
        "\n",
        "\n",
        "def bin_spikes(spike_dict, t0, t1, dt=0.001):\n",
        "    \"\"\"Bin spike times into counts per bin.\n",
        "    Returns: binned (N,T), time_edges[:-1], unit_ids(list)\n",
        "    \"\"\"\n",
        "    edges = np.arange(t0, t1 + dt, dt, dtype=float)\n",
        "    binned, unit_ids = [], []\n",
        "    for uid, st in spike_dict.items():\n",
        "        cnt, _ = np.histogram(st, bins=edges)\n",
        "        binned.append(cnt.astype(np.float32))\n",
        "        unit_ids.append(int(uid))\n",
        "    if len(binned) == 0:\n",
        "        return np.zeros((0, len(edges)-1), dtype=np.float32), edges[:-1], []\n",
        "    return np.stack(binned, axis=0), edges[:-1], unit_ids\n",
        "\n",
        "\n",
        "def session_stitch(spike_dict_list, t0, t1, dt=0.001):\n",
        "    \"\"\"Concatenate binned matrices across sessions along neuron axis.\n",
        "       Returns stitched (N_total, T)\"\"\"\n",
        "    mats = []\n",
        "    for sdict in spike_dict_list:\n",
        "        binned, _, _ = bin_spikes(sdict, t0, t1, dt)\n",
        "        mats.append(binned)\n",
        "    if len(mats) == 0:\n",
        "        return np.zeros((0, 0), dtype=np.float32)\n",
        "    return np.concatenate(mats, axis=0)"
      ],
      "metadata": {
        "id": "IbiKovRhT-kU"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# =============================\n",
        "# 2) Biological masks: Dale's law + local-only inhibition + no self-connection\n",
        "# ============================="
      ],
      "metadata": {
        "id": "0siKdZQ4TqnD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_sign_and_local_masks(area_ids, is_inh):\n",
        "    N = int(len(area_ids))\n",
        "    presyn_sign = np.where(is_inh, -1.0, +1.0).astype(np.float32)\n",
        "\n",
        "    # ✅ column-wise sign: S_sign[i,j] = sign_of_presyn(j)\n",
        "    S_sign = np.repeat(presyn_sign[None, :], N, axis=0)\n",
        "\n",
        "    aid = np.asarray(area_ids)\n",
        "    same_area = (aid[:, None] == aid[None, :]).astype(np.float32)\n",
        "\n",
        "    Lmask = np.ones((N, N), dtype=np.float32)\n",
        "    inh_rows = np.asarray(is_inh, dtype=bool)\n",
        "    Lmask[inh_rows, :] = same_area[inh_rows, :]\n",
        "\n",
        "    Dmask = np.ones((N, N), dtype=np.float32)\n",
        "    np.fill_diagonal(Dmask, 0.0)\n",
        "\n",
        "    return (torch.tensor(S_sign), torch.tensor(Lmask), torch.tensor(Dmask))"
      ],
      "metadata": {
        "id": "2eufH61IUFwe"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# =============================\n",
        "# 3) RSNN layer with constraints\n",
        "# ============================="
      ],
      "metadata": {
        "id": "yIj1uAHpTv1Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LIFLayerBio(nn.Module):\n",
        "    def __init__(self, N, S_sign, Lmask, Dmask, dt=1e-3, tau_mem=0.02, v_th=1.0, v_reset=0.0):\n",
        "        super().__init__()\n",
        "        self.N = N\n",
        "        self.dt = float(dt)\n",
        "        self.tau_mem = float(tau_mem)\n",
        "        self.alpha = float(torch.exp(torch.tensor(-self.dt / self.tau_mem)))\n",
        "        self.v_th = float(v_th)\n",
        "        self.v_reset = float(v_reset)\n",
        "\n",
        "        # 작게 초기화\n",
        "        self.W_raw = nn.Parameter(torch.randn(N, N)*1e-3)  # raw는 작은 값\n",
        "        self.W_in = nn.Parameter(torch.randn(self.N, self.N)*1e-3)  # 새로 정의 (기존 N×1은 삭제)\n",
        "\n",
        "\n",
        "        # 재귀 스케일 게인(초기 작게 시작; 학습 가능)\n",
        "        self.g_rec = nn.Parameter(torch.tensor(0.20))\n",
        "\n",
        "        # Fixed constraint buffers\n",
        "        self.register_buffer(\"S_sign\", S_sign.float())\n",
        "        self.register_buffer(\"Lmask\",  Lmask.float())\n",
        "        self.register_buffer(\"Dmask\",  Dmask.float())\n",
        "\n",
        "    def effective_W(self):\n",
        "        # ✅ softplus에 음수 오프셋 → 초기 유효가중치 거의 0\n",
        "        W_mag = F.softplus(self.W_raw - 5.0)  # softplus(≈-6) ≈ 0.0025\n",
        "        W = W_mag * self.S_sign * self.Lmask * self.Dmask\n",
        "        return self.g_rec * W  # 초기 재귀 영향 축소\n",
        "\n",
        "    def forward(self, inputs, steps=None, teacher=None, p_tf=0.0):\n",
        "        \"\"\"\n",
        "        inputs: (T, N)\n",
        "        teacher: (T, N) 타깃 시퀀스 (teacher forcing용), None이면 안 씀\n",
        "        p_tf: teacher forcing 비율 (0~1 사이)\n",
        "        \"\"\"\n",
        "        if steps is None:\n",
        "            steps = inputs.shape[0]\n",
        "        T, Nin = inputs.shape\n",
        "        assert Nin == self.N, \"Expect inputs of shape (T, N).\"\n",
        "        device = inputs.device\n",
        "        v = torch.zeros(self.N, device=device)\n",
        "        spikes = []\n",
        "        W = self.effective_W()\n",
        "\n",
        "        for t in range(T):\n",
        "            I = inputs[t]\n",
        "            I = self.W_in @ I\n",
        "            if t > 0:\n",
        "                prev_model = spikes[-1]\n",
        "                if teacher is not None and torch.rand(1).item() < p_tf:\n",
        "                    prev_sp = teacher[t - 1]  # 타겟 스파이크 사용\n",
        "                else:\n",
        "                    prev_sp = prev_model\n",
        "            else:\n",
        "                prev_sp = torch.zeros(self.N, device=device)\n",
        "\n",
        "            Irec = W @ prev_sp\n",
        "            v = self.alpha * v + (1.0 - self.alpha) * I + Irec\n",
        "            v = v.clamp(-10.0, 10.0)\n",
        "            out = torch.sigmoid((v - self.v_th) * 2.0)\n",
        "            v = v * (1.0 - out) + self.v_reset * out\n",
        "            spikes.append(out)\n",
        "\n",
        "        spikes = torch.stack(spikes)\n",
        "        if torch.isnan(spikes).any():\n",
        "            raise ValueError(\"NaN detected in spikes\")\n",
        "        return spikes"
      ],
      "metadata": {
        "id": "YLHuTy_VUIQW"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# =============================\n",
        "# 4) Training utilities (t+1 prediction)\n",
        "# ============================="
      ],
      "metadata": {
        "id": "jnsFpF0tT105"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_inputs_targets_from_binned_shift(binned_TxN, delta=1):\n",
        "    \"\"\"\n",
        "    binned_TxN: (T,N) 시퀀스\n",
        "    delta: 타깃으로 얼마나 미래를 예측할지 (기본 1 step)\n",
        "    \"\"\"\n",
        "    X = binned_TxN\n",
        "    assert delta >= 1 and delta < X.shape[0]\n",
        "    return X[:-delta], X[delta:]\n",
        "\n",
        "\n",
        "def train_tplus1(model, inp, tgt, epochs=10, lr=3e-4, lambda_in=1e-2, lambda_w1=1e-4, verbose=True):\n",
        "    opt = optim.Adam(model.parameters(), lr=lr)\n",
        "    hist = []\n",
        "\n",
        "    for ep in range(epochs):\n",
        "        opt.zero_grad()\n",
        "        spk = model(inp, steps=inp.shape[0], teacher=tgt, p_tf=0.7)  # 초반 크게, 이후 에폭마다 낮춤\n",
        "        trial_loss = ((spk - tgt) ** 2).mean()\n",
        "        psth_loss  = ((spk.mean(1) - tgt.mean(1)) ** 2).mean()\n",
        "        reg = lambda_w1 * model.effective_W().abs().mean() + lambda_in * model.W_in.abs().mean()\n",
        "        loss = 0.7 * trial_loss + 0.3 * psth_loss + reg\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        hist.append((float(loss.item()), float(trial_loss.item()), float(psth_loss.item())))\n",
        "        if verbose:\n",
        "            print(f\"Epoch {ep+1}/{epochs} | loss={loss.item():.6f} | trial={trial_loss.item():.6f} | psth={psth_loss.item():.6f}\")\n",
        "\n",
        "    return hist"
      ],
      "metadata": {
        "id": "cENfgQJ4UsXD"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# =============================\n",
        "# 5) Robustness test\n",
        "# ============================="
      ],
      "metadata": {
        "id": "VT4twDPpUOvs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def perturb_W(W, method='random', frac=0.2, scale=0.01):\n",
        "    W_new = W.clone()\n",
        "    N = W.numel()\n",
        "    k = max(1, int(frac * N))\n",
        "    idx = torch.randperm(N)[:k]\n",
        "    if method == 'random':\n",
        "        W_new.view(-1)[idx] = torch.randn_like(W_new.view(-1)[idx]) * scale\n",
        "    elif method == 'shuffle':\n",
        "        W_new.view(-1)[idx] = W_new.view(-1)[torch.randperm(N)[:k]]\n",
        "    else:\n",
        "        raise ValueError(\"Unknown method\")\n",
        "    return W_new\n",
        "\n",
        "\n",
        "def robustness_ratio(model, inp, tgt, frac=0.2):\n",
        "    with torch.no_grad():\n",
        "        spk_o = model(inp, steps=inp.shape[0])\n",
        "        loss_o = ((spk_o - tgt) ** 2).mean().item()\n",
        "\n",
        "    mpert = copy.deepcopy(model)\n",
        "    with torch.no_grad():\n",
        "        mpert.W_raw.copy_(perturb_W(mpert.W_raw, frac=frac))\n",
        "        spk_p = mpert(inp, steps=inp.shape[0])\n",
        "        loss_p = ((spk_p - tgt) ** 2).mean().item()\n",
        "    ratio = loss_p / (loss_o + 1e-12)\n",
        "    print(f\"Robustness: original={loss_o:.6f} perturbed={loss_p:.6f} ratio={ratio:.3f}\")\n",
        "    return ratio, loss_o, loss_p"
      ],
      "metadata": {
        "id": "umnWK9R6UxHU"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# =============================\n",
        "# 6) CCG utilities\n",
        "# ============================="
      ],
      "metadata": {
        "id": "8Z3Dv7YCUS0i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_ccg(sp1, sp2, max_lag_bins=50, subtract_mean=True):\n",
        "    x = sp1.astype(np.float32)\n",
        "    y = sp2.astype(np.float32)\n",
        "    if subtract_mean:\n",
        "        x = x - x.mean()\n",
        "        y = y - y.mean()\n",
        "    ccg_full = np.correlate(x, y, mode='full')\n",
        "    mid = len(ccg_full) // 2\n",
        "    return ccg_full[mid - max_lag_bins : mid + max_lag_bins + 1]\n",
        "\n",
        "\n",
        "def ccg_metrics(ccg, dt, pos_win_ms=20.0):\n",
        "    L = len(ccg)\n",
        "    half = L // 2\n",
        "    lags = (np.arange(L) - half) * dt  # seconds\n",
        "    pos_mask = (lags > 0) & (lags <= pos_win_ms / 1000.0)\n",
        "    neg_mask = (lags < 0) & (lags >= -pos_win_ms / 1000.0)\n",
        "    if not (pos_mask.any() and neg_mask.any()):\n",
        "        return np.nan, np.nan, np.nan, np.nan\n",
        "    pos_vals = ccg[pos_mask]\n",
        "    neg_vals = ccg[neg_mask]\n",
        "    pos_peak = float(pos_vals.max())\n",
        "    neg_peak = float(neg_vals.max())\n",
        "    asym = float(pos_peak - neg_peak)\n",
        "    lag_at_pos_peak = float(((np.where(pos_mask)[0])[pos_vals.argmax()] - half) * dt)\n",
        "    return pos_peak, neg_peak, asym, lag_at_pos_peak\n",
        "\n",
        "\n",
        "def ccg_vs_W_summary(binned_NxT, W_eff, dt, K=2000, max_lag_bins=50, use_abs=True, plot=False):\n",
        "    N, T = binned_NxT.shape\n",
        "    W = W_eff.detach().cpu().numpy().copy()\n",
        "    np.fill_diagonal(W, 0.0)\n",
        "    flat = W.ravel()\n",
        "    scores = np.abs(flat) if use_abs else flat\n",
        "    K = min(K, flat.size)\n",
        "    top_idx = np.argpartition(scores, -K)[-K:]\n",
        "\n",
        "    W_vals, asym_vals, pospeaks, negpeaks, lags = [], [], [], [], []\n",
        "    for idx in top_idx:\n",
        "        i, j = divmod(int(idx), N)\n",
        "        ccg = compute_ccg(binned_NxT[i], binned_NxT[j], max_lag_bins=max_lag_bins, subtract_mean=True)\n",
        "        pos_peak, neg_peak, asym, lag_pos = ccg_metrics(ccg, dt, pos_win_ms=20.0)\n",
        "        W_vals.append(W[i, j])\n",
        "        pospeaks.append(pos_peak)\n",
        "        negpeaks.append(neg_peak)\n",
        "        asym_vals.append(asym)\n",
        "        lags.append(lag_pos)\n",
        "\n",
        "    W_vals = np.array(W_vals); asym_vals = np.array(asym_vals); pospeaks = np.array(pospeaks)\n",
        "    # Simple Pearson r\n",
        "    def pearson(a, b):\n",
        "        ok = np.isfinite(a) & np.isfinite(b)\n",
        "        if ok.sum() < 2:\n",
        "            return np.nan\n",
        "        a0 = a[ok] - a[ok].mean(); b0 = b[ok] - b[ok].mean()\n",
        "        den = (np.sqrt((a0**2).sum()) * np.sqrt((b0**2).sum()) + 1e-12)\n",
        "        return float((a0*b0).sum() / den)\n",
        "\n",
        "    r_asym = pearson(W_vals, asym_vals)\n",
        "    r_posp = pearson(W_vals, pospeaks)\n",
        "\n",
        "    print(f\"CCG asym (0–20ms pos - neg) vs W: r = {r_asym:.3f}, n = {len(W_vals)}\")\n",
        "    print(f\"CCG pos-lag peak (0–20ms) vs W:  r = {r_posp:.3f}, n = {len(W_vals)}\")\n",
        "\n",
        "    if plot:\n",
        "        plt.figure(figsize=(5,4)); plt.scatter(W_vals, asym_vals, s=6, alpha=0.3)\n",
        "        plt.xlabel(\"W_ij\"); plt.ylabel(\"CCG asym 0–20ms\"); plt.title(f\"r={r_asym:.3f}\")\n",
        "        plt.tight_layout(); plt.show()\n",
        "        plt.figure(figsize=(5,4)); plt.scatter(W_vals, pospeaks, s=6, alpha=0.3)\n",
        "        plt.xlabel(\"W_ij\"); plt.ylabel(\"CCG pos-lag peak 0–20ms\"); plt.title(f\"r={r_posp:.3f}\")\n",
        "        plt.tight_layout(); plt.show()\n",
        "\n",
        "    return {\n",
        "        'W': W_vals,\n",
        "        'asym': asym_vals,\n",
        "        'pospeak': pospeaks,\n",
        "        'r_asym': r_asym,\n",
        "        'r_pospeak': r_posp,\n",
        "        'lags': np.array(lags),\n",
        "    }"
      ],
      "metadata": {
        "id": "k3Eep02JU3WM"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# =============================\n",
        "# 7) Holography simulation (opsin drive)\n",
        "# ============================="
      ],
      "metadata": {
        "id": "kh1aVNBrUZyh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_opsin_kernel(dt, tau_r=0.003, tau_d=0.030, dur=0.200, A=0.01):\n",
        "    T = int(dur / dt) + 1\n",
        "    t = np.arange(T, dtype=float) * dt\n",
        "    k = A * (np.exp(-t / tau_d) - np.exp(-t / tau_r))\n",
        "    k[k < 0] = 0.0\n",
        "    return k.astype(np.float32)\n",
        "\n",
        "\n",
        "def build_photo_drive(N, T, stim_events, dt, A=1.0, tau_r=0.003, tau_d=0.030):\n",
        "    photo = np.zeros((T, N), dtype=np.float32)\n",
        "    base_k = make_opsin_kernel(dt, tau_r, tau_d, dur=0.5, A=A)\n",
        "    for ev in stim_events:\n",
        "        cells = ev[\"cells\"]\n",
        "        t_on  = ev[\"t_on\"]; dur = ev.get(\"dur\", 0.050)\n",
        "        power = float(ev.get(\"power\", 1.0))\n",
        "        k = base_k * power\n",
        "        L = len(k)\n",
        "        t0 = int(t_on / dt)\n",
        "        t1 = min(T, t0 + L)\n",
        "        for c in cells:\n",
        "            if 0 <= c < N:\n",
        "                photo[t0:t1, c] += k[:(t1 - t0)]\n",
        "    return photo\n",
        "\n",
        "\n",
        "def window_counts(spikes_TxN, t_on, dt, win=(0.0, 0.020), cells=None, thresh=0.5):\n",
        "    T, N = spikes_TxN.shape\n",
        "    i0 = max(0, int((t_on + win[0]) / dt))\n",
        "    i1 = min(T, int((t_on + win[1]) / dt))\n",
        "    if cells is None:\n",
        "        cells = np.arange(N)\n",
        "    s = (spikes_TxN > thresh).astype(np.float32)\n",
        "    return s[i0:i1, cells].sum(axis=0)\n",
        "\n",
        "\n",
        "def latency_ms(spikes_TxN, t_on, dt, cells, thresh=0.5):\n",
        "    T, N = spikes_TxN.shape\n",
        "    idx_on = int(t_on / dt)\n",
        "    sbin = (spikes_TxN > thresh).astype(np.float32)\n",
        "    lats = []\n",
        "    for c in cells:\n",
        "        post = np.where(sbin[idx_on:, c] > 0)[0]\n",
        "        if post.size == 0:\n",
        "            lats.append(np.nan)\n",
        "        else:\n",
        "            lats.append(float(post[0] * dt * 1000.0))\n",
        "    return np.array(lats)\n",
        "\n",
        "\n",
        "def run_holography_protocol(model, base_inputs_TxN, dt, stim_cells_sets, t_on=2.0, powers=(0.2,0.4,0.6,0.8,1.0)):\n",
        "    \"\"\"Return dose–response stats per cell-set.\n",
        "       stim_cells_sets: list of lists of cell indices (e.g., [[10], [101,205,309], ...])\n",
        "    \"\"\"\n",
        "    device = base_inputs_TxN.device\n",
        "    T, N = base_inputs_TxN.shape\n",
        "    base = base_inputs_TxN\n",
        "    results = []\n",
        "\n",
        "    # Baseline trial (no photo)\n",
        "    with torch.no_grad():\n",
        "        spk_base = model(base, steps=T).detach().cpu().numpy()\n",
        "\n",
        "    for cells in stim_cells_sets:\n",
        "        cell_list = list(cells)\n",
        "        dose = []\n",
        "        for p in powers:\n",
        "            photo = build_photo_drive(N, T, [{\"cells\": cell_list, \"t_on\": t_on, \"power\": p, \"dur\": 0.050}], dt=dt, A=1.0)\n",
        "            inp_aug = base.detach().cpu().numpy() + photo\n",
        "            inp_aug = torch.tensor(inp_aug, dtype=torch.float32, device=device)\n",
        "            with torch.no_grad():\n",
        "                spk = model(inp_aug, steps=T).detach().cpu().numpy()\n",
        "            # Simple metrics\n",
        "            cnt = window_counts(spk, t_on=t_on, dt=dt, win=(0.0, 0.020), cells=cell_list, thresh=0.9).mean()\n",
        "            lat = np.nanmean(latency_ms(spk, t_on=t_on, dt=dt, cells=cell_list))\n",
        "            dose.append((float(p), float(cnt), float(lat)))\n",
        "        results.append({\"cells\": cell_list, \"dose\": dose})\n",
        "\n",
        "    # Optional: print summary\n",
        "    for r in results:\n",
        "        print(f\"Stim cells {r['cells']}: \")\n",
        "        for (p, cnt, lat) in r[\"dose\"]:\n",
        "            print(f\"  power={p:.2f} -> mean count(0–20ms)={cnt:.3f}, latency_ms={lat:.1f}\")\n",
        "    return results"
      ],
      "metadata": {
        "id": "L6H8wwf2V-A5"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# =============================\n",
        "# 8) Main pipeline\n",
        "# ============================="
      ],
      "metadata": {
        "id": "EVstkmOXUe6T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    # ---- USER CONFIG ----\n",
        "    session_files = [\n",
        "        r\"/content/drive/MyDrive/Neuropixel/sub-619293_ses-1184980079_ogen.nwb\",\n",
        "        r\"/content/drive/MyDrive/Neuropixel/sub-619296_ses-1187930705_ogen.nwb\"\n",
        "    ]\n",
        "    t0, t1, dt = 0.0, 10.0, 0.001  # 10 seconds @ 1ms bins\n",
        "\n",
        "    if len(session_files) and HAS_NWB:\n",
        "        spike_dict_list = [load_spikes_from_nwb(f) for f in session_files]\n",
        "        stitched = session_stitch(spike_dict_list, t0, t1, dt)\n",
        "    else:\n",
        "        raise RuntimeError(\"Please provide NWB paths in session_files.\")\n",
        "\n",
        "    print(\"Stitched spike shape:\", stitched.shape)  # (N, T)\n",
        "    if stitched.size == 0:\n",
        "        raise RuntimeError(\"No spikes loaded.\")\n",
        "\n",
        "    # Use raw binned; clip to 0/1 for 5ms bins\n",
        "    stitched = np.clip(stitched, 0, 1).astype(np.float32)\n",
        "\n",
        "    # Build tensors (T,N)\n",
        "    X = torch.tensor(stitched.T, dtype=torch.float32, device=device)\n",
        "    T, N = X.shape\n",
        "\n",
        "    # Masks (replace with real labels if available)\n",
        "    area_ids = np.zeros(N, dtype=int)         # default: single area\n",
        "    is_inh   = np.zeros(N, dtype=bool)\n",
        "    is_inh[::5] = True                        # ~20% inhibitory\n",
        "\n",
        "    S_sign, Lmask, Dmask = build_sign_and_local_masks(area_ids, is_inh)\n",
        "\n",
        "    # Model\n",
        "    model = LIFLayerBio(N, S_sign.to(device), Lmask.to(device), Dmask.to(device), dt=dt).to(device)\n",
        "\n",
        "    # t+1 prediction setup\n",
        "    # Δ를 고정하거나 랜덤으로 뽑기\n",
        "    delta = np.random.randint(1, 6)  # 1~5 step 랜덤\n",
        "    inp, tgt = make_inputs_targets_from_binned_shift(X, delta=delta)\n",
        "\n",
        "\n",
        "\n",
        "    # Train\n",
        "    _ = train_tplus1(model, inp, tgt, epochs=10, lr=1e-2, lambda_in=0.0, lambda_w1=1e-5, verbose=True)\n",
        "\n",
        "    # Robustness\n",
        "    _ratio, _lo, _lp = robustness_ratio(model, inp, tgt, frac=0.2)\n",
        "\n",
        "    # CCG vs W on top-|W| pairs\n",
        "    with torch.no_grad():\n",
        "        W_eff = model.effective_W()\n",
        "    ccg_res = ccg_vs_W_summary(binned_NxT=stitched, W_eff=W_eff, dt=dt, K=2000, max_lag_bins=50, use_abs=True, plot=False)\n",
        "\n",
        "    # Holography demo: single cell + small ensemble\n",
        "    stim_sets = [ [10], [101, 205, 309] ] if N > 310 else [ [min(10, N-1)], list(np.unique(np.linspace(0, N-1, num=min(3, N), dtype=int))) ]\n",
        "    holo = run_holography_protocol(model, X, dt, stim_sets, t_on=2.013, powers=(0.2,0.4,0.6,0.8,1.2))\n",
        "\n",
        "    print(\"Done.\")"
      ],
      "metadata": {
        "id": "Sd3EUzqAWvHI"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "6aqY_BgPS0h7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae5bdce7-ad82-461a-f256-97aceb07ac5e"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stitched spike shape: (4054, 10000)\n",
            "Epoch 1/10 | loss=0.127306 | trial=0.128069 | psth=0.125526\n",
            "Epoch 2/10 | loss=0.115951 | trial=0.116717 | psth=0.114163\n",
            "Epoch 3/10 | loss=0.102357 | trial=0.103135 | psth=0.100543\n",
            "Epoch 4/10 | loss=0.095498 | trial=0.096297 | psth=0.093632\n",
            "Epoch 5/10 | loss=0.082498 | trial=0.083335 | psth=0.080546\n",
            "Epoch 6/10 | loss=0.067241 | trial=0.068136 | psth=0.065152\n",
            "Epoch 7/10 | loss=0.054617 | trial=0.055603 | psth=0.052316\n",
            "Epoch 8/10 | loss=0.036891 | trial=0.038165 | psth=0.033918\n",
            "Epoch 9/10 | loss=0.033868 | trial=0.035205 | psth=0.030747\n",
            "Epoch 10/10 | loss=0.031575 | trial=0.032967 | psth=0.028327\n",
            "Robustness: original=0.470321 perturbed=0.491713 ratio=1.045\n",
            "CCG asym (0–20ms pos - neg) vs W: r = -0.026, n = 2000\n",
            "CCG pos-lag peak (0–20ms) vs W:  r = 0.043, n = 2000\n",
            "Stim cells [10]: \n",
            "  power=0.20 -> mean count(0–20ms)=0.000, latency_ms=0.0\n",
            "  power=0.40 -> mean count(0–20ms)=0.000, latency_ms=0.0\n",
            "  power=0.60 -> mean count(0–20ms)=0.000, latency_ms=0.0\n",
            "  power=0.80 -> mean count(0–20ms)=0.000, latency_ms=0.0\n",
            "  power=1.20 -> mean count(0–20ms)=0.000, latency_ms=0.0\n",
            "Stim cells [101, 205, 309]: \n",
            "  power=0.20 -> mean count(0–20ms)=0.000, latency_ms=0.0\n",
            "  power=0.40 -> mean count(0–20ms)=0.000, latency_ms=0.0\n",
            "  power=0.60 -> mean count(0–20ms)=0.000, latency_ms=0.0\n",
            "  power=0.80 -> mean count(0–20ms)=0.000, latency_ms=0.0\n",
            "  power=1.20 -> mean count(0–20ms)=0.000, latency_ms=0.0\n",
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def find_responsive_neurons(spike_dict, stim_events, dt=0.001, win_ms=50.0):\n",
        "    \"\"\"\n",
        "    Finds neurons that show a significant increase in spiking activity after holographic stimulation.\n",
        "    Returns a list of responsive neuron IDs.\n",
        "    \"\"\"\n",
        "    responsive_neurons = set()\n",
        "    win_bins = int(win_ms / 1000.0 / dt)\n",
        "\n",
        "    for ev in stim_events:\n",
        "        t_on = ev[\"t_on\"]\n",
        "        stim_cells = ev.get(\"cells\", [])\n",
        "\n",
        "        # 1. 대상 뉴런들의 스파이크 데이터 추출\n",
        "        for unit_id in stim_cells:\n",
        "            if unit_id not in spike_dict:\n",
        "                continue\n",
        "\n",
        "            spike_times = spike_dict[unit_id]\n",
        "            t_start = t_on - win_ms / 1000.0\n",
        "\n",
        "            # 2. 기준선 및 반응 윈도우의 스파이크 수 계산\n",
        "            baseline_spikes = np.sum((spike_times >= t_start) & (spike_times < t_on))\n",
        "            response_spikes = np.sum((spike_times >= t_on) & (spike_times < t_on + win_ms / 1000.0))\n",
        "\n",
        "            # 3. 유의미한 스파이크 수 증가 확인\n",
        "            # 간단한 임계치 또는 통계 테스트(예: t-test)를 사용\n",
        "            if response_spikes > baseline_spikes * 1.5 and response_spikes > 10:  # 예시 임계치\n",
        "                responsive_neurons.add(unit_id)\n",
        "\n",
        "    return list(responsive_neurons)"
      ],
      "metadata": {
        "id": "iqRTx3rSJxq1"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 예시 사용법\n",
        "nwb_file = \"/content/drive/MyDrive/Neuropixel/sub-619296_ses-1187930705_ogen.nwb\"\n",
        "io = NWBHDF5IO(nwb_file, 'r')\n",
        "nwbfile = io.read()\n",
        "\n",
        "# Placeholder function for get_stimulation_events\n",
        "def get_stimulation_events(nwbfile):\n",
        "    \"\"\"\n",
        "    Placeholder function to extract stimulation events from NWB file.\n",
        "    Replace with actual implementation based on NWB file structure.\n",
        "    Returns a list of dictionaries, each with 't_on' and 'cells'.\n",
        "    \"\"\"\n",
        "    # Example placeholder events\n",
        "    return [\n",
        "        {\"t_on\": 2.013, \"cells\": [10]},\n",
        "        {\"t_on\": 2.013, \"cells\": [101, 205, 309]},\n",
        "    ]\n",
        "\n",
        "\n",
        "stim_events_from_nwb = get_stimulation_events(nwbfile) # NWB에서 자극 정보 추출 필요\n",
        "spike_data = load_spikes_from_nwb(nwb_file)\n",
        "responsive_list = find_responsive_neurons(spike_data, stim_events_from_nwb)\n",
        "print(f\"Found {len(responsive_list)} responsive neuron(s):\")\n",
        "print(responsive_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5TpZB5gOJ_jp",
        "outputId": "9b6feb0a-6198-4135-d217-0f175d036f52"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 0 responsive neuron(s):\n",
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39a9f68f"
      },
      "source": [
        "# Task\n",
        "Analyze the current results of the RSNN model fitting, focusing on the robustness ratio, CCG correlation, and holography simulation output. Based on this analysis, identify and implement improvements to the model and training process to address the observed issues, specifically the low robustness ratio, poor CCG correspondence, and lack of response in the holography simulation. Re-run the model and evaluate the impact of the changes on the performance metrics. Continue iterating on the model and training until satisfactory results are achieved for both Aim 1 (connectivity estimation validation) and Aim 2 (recapitulating holography results). Finally, summarize the findings and present the improved model and its performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cc1b4074"
      },
      "source": [
        "## Analyze current results\n",
        "\n",
        "### Subtask:\n",
        "Review the outputs from the last execution, focusing on the robustness ratio, CCG correlation values (`r_asym`, `r_pospeak`), and the holography simulation output (mean counts and latencies). This will help pinpoint the extent of the issues in each area.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ce8a0097"
      },
      "source": [
        "**Reasoning**:\n",
        "Review the output from the previous execution to identify the key performance metrics: robustness ratio, CCG correlations (asymmetry and positive lag peak), and holography simulation results (mean counts and latencies).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76dbcd99"
      },
      "source": [
        "# Reviewing the output from the previous execution:\n",
        "# Robustness ratio: Look for the line starting with \"Robustness:\".\n",
        "# CCG correlations: Look for lines starting with \"CCG asym\" and \"CCG pos-lag peak\".\n",
        "# Holography simulation: Look for the section starting with \"Stim cells\".\n",
        "\n",
        "# Based on the provided output:\n",
        "robustness_ratio_value = 1.027  # From \"Robustness: original=0.281640 perturbed=0.289195 ratio=1.027\"\n",
        "ccg_asym_r = 0.022            # From \"CCG asym (0–20ms pos - neg) vs W: r = 0.022, n = 2000\"\n",
        "ccg_pospeak_r = 0.848         # From \"CCG pos-lag peak (0–20ms) vs W: r = 0.848, n = 2000\"\n",
        "\n",
        "# Holography simulation results (from \"Stim cells\" section):\n",
        "# For Stim cells [10]: mean counts and latencies are all 0.000 and 0.0 respectively across all power levels.\n",
        "# For Stim cells [101, 205, 309]: mean counts and latencies are all 0.000 and 0.0 respectively across all power levels.\n",
        "\n",
        "print(f\"Robustness Ratio: {robustness_ratio_value}\")\n",
        "print(f\"CCG Asymmetry Correlation (r): {ccg_asym_r}\")\n",
        "print(f\"CCG Positive Peak Correlation (r): {ccg_pospeak_r}\")\n",
        "print(\"Holography Simulation Results:\")\n",
        "print(\"Stim cells [10]: Mean counts and latencies are all zero.\")\n",
        "print(\"Stim cells [101, 205, 309]: Mean counts and latencies are all zero.\")\n",
        "\n",
        "# Summarize the current state:\n",
        "print(\"\\nSummary of Current Model Performance:\")\n",
        "print(f\"- Robustness: The ratio ({robustness_ratio_value:.3f}) is close to 1, indicating the model's performance is not highly sensitive to random perturbations of effective weights.\")\n",
        "print(f\"- Learned Connectivity (CCG): The correlation between effective weights and CCG asymmetry ({ccg_asym_r:.3f}) is very low, suggesting that the learned connectivity doesn't strongly reflect the expected asymmetric structure related to synaptic transmission delays. The correlation with the positive peak ({ccg_pospeak_r:.3f}) is high, which is a positive sign for predicting the timing of postsynaptic responses, but the asymmetry is a more direct measure of directed connectivity.\")\n",
        "print(f\"- Holography Simulation: The simulation shows no response (zero mean counts and latencies) for both single-cell and ensemble stimulation across all tested power levels. This indicates that the model is currently unable to recapitulate the expected excitatory responses to optogenetic stimulation.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18f6dc35"
      },
      "source": [
        "# Task\n",
        "Analyze and improve the recurrent spiking neural network (RSNN) model based on illusory contour Neuropixels data to accurately estimate connectivity (Aim 1) and recapitulate holography experiment results (Aim 2). This involves investigating current unsatisfactory results (low robustness ratio, poor CCG correlation, zero mean counts, and problematic latencies in holography simulation), adjusting model parameters and training configurations, and iteratively evaluating the performance against the defined metrics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fe367b1"
      },
      "source": [
        "## Analyze current results\n",
        "\n",
        "### Subtask:\n",
        "Review the outputs from the last execution, focusing on the robustness ratio, CCG correlation values (`r_asym`, `r_pospeak`), and the holography simulation output (mean counts and latencies) for both single cell and ensemble stimulation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ade2324a"
      },
      "source": [
        "## Investigate robustness and training stability\n",
        "\n",
        "### Subtask:\n",
        "Examine the training loss over 50 epochs to see if it's converging or becoming unstable. Analyze the magnitude of the learned weights (`W_eff`) to understand if they are growing too large or remaining too small, which could affect robustness and CCG correspondence.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ef7c4b2f"
      },
      "source": [
        "**Reasoning**:\n",
        "Extract loss history from the `hist` variable, calculate statistics for the effective weights, and then plot the loss history to visualize training progress and analyze the weight distribution.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "id": "d2ae052c",
        "outputId": "1e946aeb-dad0-45f8-eed6-c22facbb9302"
      },
      "source": [
        "# Access the hist variable from the previous execution\n",
        "# hist = [(loss.item(), trial_loss.item(), psth_loss.item()) for ep in range(epochs)]\n",
        "# Assuming 'hist' variable is accessible from the previous training run\n",
        "# If not, you might need to re-run the training part or make 'hist' global\n",
        "\n",
        "# Extract loss values\n",
        "total_loss = [h[0] for h in hist]\n",
        "trial_loss = [h[1] for h in hist]\n",
        "psth_loss = [h[2] for h in hist]\n",
        "epochs_range = range(1, len(hist) + 1)\n",
        "\n",
        "# Plot the loss history\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(epochs_range, total_loss, label='Total Loss')\n",
        "plt.plot(epochs_range, trial_loss, label='Trial Loss')\n",
        "plt.plot(epochs_range, psth_loss, label='PSTH Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Loss Over Epochs')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Access the effective_W tensor from the trained model\n",
        "with torch.no_grad():\n",
        "    effective_W = model.effective_W()\n",
        "\n",
        "# Calculate and print statistics for effective_W\n",
        "print(\"\\nStatistics for effective_W:\")\n",
        "print(f\"Mean: {effective_W.mean().item():.6f}\")\n",
        "print(f\"Standard Deviation: {effective_W.std().item():.6f}\")\n",
        "print(f\"Min: {effective_W.min().item():.6f}\")\n",
        "print(f\"Max: {effective_W.max().item():.6f}\")\n",
        "print(f\"Median: {effective_W.median().item():.6f}\")\n",
        "print(f\"Number of non-zero elements: {(effective_W != 0).sum().item()}\")\n",
        "print(f\"Sparsity: {1.0 - (effective_W != 0).sum().item() / effective_W.numel():.6f}\")"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Statistics for effective_W:\n",
            "Mean: -0.000223\n",
            "Standard Deviation: 0.000335\n",
            "Min: -0.000440\n",
            "Max: 0.000454\n",
            "Median: -0.000386\n",
            "Number of non-zero elements: 16430862\n",
            "Sparsity: 0.000247\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f921a86c"
      },
      "source": [
        "**Reasoning**:\n",
        "The `hist` variable was not accessible because it was local to the `train_tplus1` function and the `main` function where it was called. To fix this, I will modify the `train_tplus1` function to return the `hist` variable and modify the `main` function to capture this return value. Then I will rerun the `main` function. After rerunning `main`, `hist` will be available, and I can then proceed to plot the loss and analyze the weights in a subsequent step.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zmIS0UWO_vp5",
        "outputId": "c6a3e197-f4e8-4a1d-8256-ac499c5aef40"
      },
      "source": [
        "# Modify the train_tplus1 function to return hist\n",
        "def train_tplus1(model, inp, tgt, epochs=10, lr=3e-4, lambda_in=1e-2, lambda_w1=1e-4, verbose=True):\n",
        "    opt = optim.Adam(model.parameters(), lr=lr)\n",
        "    hist = []\n",
        "\n",
        "    for ep in range(epochs):\n",
        "        opt.zero_grad()\n",
        "        spk = model(inp, steps=inp.shape[0], teacher=tgt, p_tf=0.7)\n",
        "        trial_loss = ((spk - tgt) ** 2).mean()\n",
        "        psth_loss  = ((spk.mean(1) - tgt.mean(1)) ** 2).mean()\n",
        "        reg = lambda_w1 * model.effective_W().abs().mean() + lambda_in * model.W_in.abs().mean()\n",
        "        loss = 0.7 * trial_loss + 0.3 * psth_loss + reg\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        hist.append((float(loss.item()), float(trial_loss.item()), float(psth_loss.item())))\n",
        "        if verbose:\n",
        "            print(f\"Epoch {ep+1}/{epochs} | loss={loss.item():.6f} | trial={trial_loss.item():.6f} | psth={psth_loss.item():.6f}\")\n",
        "\n",
        "    return hist # Return hist\n",
        "\n",
        "# Modify the main function to capture the returned hist and make it accessible (e.g., global or return)\n",
        "def main():\n",
        "    global hist # Make hist globally accessible for analysis later\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    # ---- USER CONFIG ----\n",
        "    session_files = [\n",
        "        \"/content/drive/MyDrive/Neuropixel/sub-619293_ses-1184980079_ogen.nwb\",\n",
        "        \"/content/drive/MyDrive/Neuropixel/sub-619296_ses-1187930705_ogen.nwb\",\n",
        "    ]\n",
        "    t0, t1, dt = 0.0, 10.0, 0.005  # 10 seconds @ 5 ms bins\n",
        "\n",
        "    if len(session_files) and HAS_NWB:\n",
        "        spike_dict_list = [load_spikes_from_nwb(f) for f in session_files]\n",
        "        stitched = session_stitch(spike_dict_list, t0, t1, dt)\n",
        "    else:\n",
        "        raise RuntimeError(\"Please provide NWB paths in session_files.\")\n",
        "\n",
        "    print(\"Stitched spike shape:\", stitched.shape)  # (N, T)\n",
        "    if stitched.size == 0:\n",
        "        raise RuntimeError(\"No spikes loaded.\")\n",
        "\n",
        "    # Use raw binned; clip to 0/1 for 5ms bins\n",
        "    stitched = np.clip(stitched, 0, 1).astype(np.float32)\n",
        "\n",
        "    # Build tensors (T,N)\n",
        "    X = torch.tensor(stitched.T, dtype=torch.float32, device=device)\n",
        "    T, N = X.shape\n",
        "\n",
        "    # Masks (replace with real labels if available)\n",
        "    area_ids = np.zeros(N, dtype=int)         # default: single area\n",
        "    is_inh   = np.zeros(N, dtype=bool)\n",
        "    is_inh[::5] = True                        # ~20% inhibitory\n",
        "\n",
        "    S_sign, Lmask, Dmask = build_sign_and_local_masks(area_ids, is_inh)\n",
        "\n",
        "    # Model\n",
        "    global model # Make model globally accessible for analysis later\n",
        "    model = LIFLayerBio(N, S_sign.to(device), Lmask.to(device), Dmask.to(device), dt=dt).to(device)\n",
        "\n",
        "    # t+1 prediction setup\n",
        "    delta = np.random.randint(1, 6)  # 1~5 step 랜덤\n",
        "    inp, tgt = make_inputs_targets_from_binned_shift(X, delta=delta)\n",
        "\n",
        "    # Train\n",
        "    hist = train_tplus1(model, inp, tgt, epochs=50, lr=1e-2, lambda_in=0.0, lambda_w1=1e-5, verbose=True) # Capture the returned hist\n",
        "\n",
        "    # Robustness\n",
        "    _ratio, _lo, _lp = robustness_ratio(model, inp, tgt, frac=0.2)\n",
        "\n",
        "    # CCG vs W on top-|W| pairs\n",
        "    with torch.no_grad():\n",
        "        W_eff = model.effective_W()\n",
        "    ccg_res = ccg_vs_W_summary(binned_NxT=stitched, W_eff=W_eff, dt=dt, K=2000, max_lag_bins=50, use_abs=True, plot=False)\n",
        "\n",
        "    # Holography demo: single cell + small ensemble\n",
        "    stim_sets = [ [10], [101, 205, 309] ] if N > 310 else [ [min(10, N-1)], list(np.unique(np.linspace(0, N-1, num=min(3, N), dtype=int))) ]\n",
        "    holo = run_holography_protocol(model, X, dt, stim_sets, t_on=2.013, powers=(0.2,0.4,0.6,0.8,1.2))\n",
        "\n",
        "    print(\"Done.\")\n",
        "\n",
        "# Re-run the main function to train the model and make 'hist' and 'model' available\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stitched spike shape: (4054, 2001)\n",
            "Epoch 1/50 | loss=0.648108 | trial=0.651771 | psth=0.639558\n",
            "Epoch 2/50 | loss=0.671722 | trial=0.675385 | psth=0.663171\n",
            "Epoch 3/50 | loss=0.663730 | trial=0.667393 | psth=0.655179\n",
            "Epoch 4/50 | loss=0.675479 | trial=0.679142 | psth=0.666929\n",
            "Epoch 5/50 | loss=0.674819 | trial=0.678482 | psth=0.666269\n",
            "Epoch 6/50 | loss=0.667136 | trial=0.670799 | psth=0.658586\n",
            "Epoch 7/50 | loss=0.673148 | trial=0.676811 | psth=0.664598\n",
            "Epoch 8/50 | loss=0.667873 | trial=0.671536 | psth=0.659324\n",
            "Epoch 9/50 | loss=0.658508 | trial=0.662170 | psth=0.649958\n",
            "Epoch 10/50 | loss=0.660562 | trial=0.664224 | psth=0.652014\n",
            "Epoch 11/50 | loss=0.662161 | trial=0.665823 | psth=0.653615\n",
            "Epoch 12/50 | loss=0.650397 | trial=0.654058 | psth=0.641852\n",
            "Epoch 13/50 | loss=0.660344 | trial=0.664004 | psth=0.651802\n",
            "Epoch 14/50 | loss=0.642804 | trial=0.646462 | psth=0.634266\n",
            "Epoch 15/50 | loss=0.634510 | trial=0.638165 | psth=0.625980\n",
            "Epoch 16/50 | loss=0.603118 | trial=0.606770 | psth=0.594596\n",
            "Epoch 17/50 | loss=0.580106 | trial=0.583754 | psth=0.571593\n",
            "Epoch 18/50 | loss=0.521435 | trial=0.525079 | psth=0.512933\n",
            "Epoch 19/50 | loss=0.476625 | trial=0.480265 | psth=0.468131\n",
            "Epoch 20/50 | loss=0.417481 | trial=0.421117 | psth=0.408996\n",
            "Epoch 21/50 | loss=0.347701 | trial=0.351330 | psth=0.339233\n",
            "Epoch 22/50 | loss=0.202226 | trial=0.205838 | psth=0.193797\n",
            "Epoch 23/50 | loss=0.010246 | trial=0.013856 | psth=0.001821\n",
            "Epoch 24/50 | loss=0.009564 | trial=0.013212 | psth=0.001051\n",
            "Epoch 25/50 | loss=0.009390 | trial=0.013048 | psth=0.000855\n",
            "Epoch 26/50 | loss=0.009290 | trial=0.012951 | psth=0.000746\n",
            "Epoch 27/50 | loss=0.009365 | trial=0.013027 | psth=0.000818\n",
            "Epoch 28/50 | loss=0.009398 | trial=0.013061 | psth=0.000850\n",
            "Epoch 29/50 | loss=0.009250 | trial=0.012914 | psth=0.000701\n",
            "Epoch 30/50 | loss=0.009182 | trial=0.012845 | psth=0.000633\n",
            "Epoch 31/50 | loss=0.009331 | trial=0.012995 | psth=0.000782\n",
            "Epoch 32/50 | loss=0.009138 | trial=0.012802 | psth=0.000589\n",
            "Epoch 33/50 | loss=0.009206 | trial=0.012870 | psth=0.000656\n",
            "Epoch 34/50 | loss=0.009263 | trial=0.012927 | psth=0.000713\n",
            "Epoch 35/50 | loss=0.009181 | trial=0.012845 | psth=0.000632\n",
            "Epoch 36/50 | loss=0.009227 | trial=0.012890 | psth=0.000677\n",
            "Epoch 37/50 | loss=0.009219 | trial=0.012883 | psth=0.000670\n",
            "Epoch 38/50 | loss=0.009204 | trial=0.012868 | psth=0.000655\n",
            "Epoch 39/50 | loss=0.009158 | trial=0.012822 | psth=0.000609\n",
            "Epoch 40/50 | loss=0.009163 | trial=0.012827 | psth=0.000613\n",
            "Epoch 41/50 | loss=0.009198 | trial=0.012861 | psth=0.000648\n",
            "Epoch 42/50 | loss=0.009203 | trial=0.012866 | psth=0.000653\n",
            "Epoch 43/50 | loss=0.009204 | trial=0.012868 | psth=0.000654\n",
            "Epoch 44/50 | loss=0.009259 | trial=0.012922 | psth=0.000709\n",
            "Epoch 45/50 | loss=0.009335 | trial=0.012998 | psth=0.000785\n",
            "Epoch 46/50 | loss=0.009146 | trial=0.012809 | psth=0.000596\n",
            "Epoch 47/50 | loss=0.009144 | trial=0.012808 | psth=0.000594\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-798128524.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;31m# Re-run the main function to train the model and make 'hist' and 'model' available\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-798128524.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m     \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_tplus1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_in\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_w1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Capture the returned hist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;31m# Robustness\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-798128524.py\u001b[0m in \u001b[0;36mtrain_tplus1\u001b[0;34m(model, inp, tgt, epochs, lr, lambda_in, lambda_w1, verbose)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mreg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlambda_w1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meffective_W\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlambda_in\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_in\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.7\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtrial_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.3\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mpsth_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mreg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpsth_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    645\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m             )\n\u001b[0;32m--> 647\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    648\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    355\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    827\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 829\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    830\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a94b3114"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the `hist` and `model` variables are accessible globally after rerunning the `main` function, I can proceed with plotting the training loss history and analyzing the statistics of the effective weights as per the subtask instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8-cIPVYBhd2"
      },
      "source": [
        "# Extract loss values from the globally accessible 'hist' variable\n",
        "total_loss = [h[0] for h in hist]\n",
        "trial_loss = [h[1] for h in hist]\n",
        "psth_loss = [h[2] for h in hist]\n",
        "epochs_range = range(1, len(hist) + 1)\n",
        "\n",
        "# Plot the loss history\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(epochs_range, total_loss, label='Total Loss')\n",
        "plt.plot(epochs_range, trial_loss, label='Trial Loss')\n",
        "plt.plot(epochs_range, psth_loss, label='PSTH Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Loss Over Epochs')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Access the effective_W tensor from the globally accessible 'model' object\n",
        "with torch.no_grad():\n",
        "    effective_W = model.effective_W()\n",
        "\n",
        "# Calculate and print statistics for effective_W\n",
        "print(\"\\nStatistics for effective_W:\")\n",
        "print(f\"Mean: {effective_W.mean().item():.6f}\")\n",
        "print(f\"Standard Deviation: {effective_W.std().item():.6f}\")\n",
        "print(f\"Min: {effective_W.min().item():.6f}\")\n",
        "print(f\"Max: {effective_W.max().item():.6f}\")\n",
        "print(f\"Median: {effective_W.median().item():.6f}\")\n",
        "print(f\"Number of non-zero elements: {(effective_W != 0).sum().item()}\")\n",
        "print(f\"Sparsity: {1.0 - (effective_W != 0).sum().item() / effective_W.numel():.6f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11efaba4"
      },
      "source": [
        "## Improve ccg correspondence\n",
        "\n",
        "### Subtask:\n",
        "Experiment with different regularization strengths (`lambda_w1`) in `train_tplus1` to improve the correlation between effective weights and CCG asymmetry and positive peak. Consider if adjusting other training parameters (like learning rate or optimizer) could improve convergence for CCG correlation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "681ee973"
      },
      "source": [
        "**Reasoning**:\n",
        "Modify the main function to iterate through different values of lambda_w1, re-run the training and evaluation for each value, and print the resulting CCG correlations to observe the effect of regularization strength.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91a70f55"
      },
      "source": [
        "def main_with_lambda(lambda_w1_val):\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    # ---- USER CONFIG ----\n",
        "    session_files = [\n",
        "        \"/content/drive/MyDrive/Neuropixel/sub-619293_ses-1184980079_ogen.nwb\",\n",
        "        \"/content/drive/MyDrive/Neuropixel/sub-619296_ses-1187930705_ogen.nwb\",\n",
        "    ]\n",
        "    t0, t1, dt = 0.0, 10.0, 0.005  # 10 seconds @ 5 ms bins\n",
        "\n",
        "    if len(session_files) and HAS_NWB:\n",
        "        spike_dict_list = [load_spikes_from_nwb(f) for f in session_files]\n",
        "        stitched = session_stitch(spike_dict_list, t0, t1, dt)\n",
        "    else:\n",
        "        raise RuntimeError(\"Please provide NWB paths in session_files.\")\n",
        "\n",
        "    print(f\"Running with lambda_w1 = {lambda_w1_val}\")\n",
        "    print(\"Stitched spike shape:\", stitched.shape)  # (N, T)\n",
        "    if stitched.size == 0:\n",
        "        raise RuntimeError(\"No spikes loaded.\")\n",
        "\n",
        "    # Use raw binned; clip to 0/1 for 5ms bins\n",
        "    stitched = np.clip(stitched, 0, 1).astype(np.float32)\n",
        "\n",
        "    # Build tensors (T,N)\n",
        "    X = torch.tensor(stitched.T, dtype=torch.float32, device=device)\n",
        "    T, N = X.shape\n",
        "\n",
        "    # Masks (replace with real labels if available)\n",
        "    area_ids = np.zeros(N, dtype=int)         # default: single area\n",
        "    is_inh   = np.zeros(N, dtype=bool)\n",
        "    is_inh[::5] = True                        # ~20% inhibitory\n",
        "\n",
        "    S_sign, Lmask, Dmask = build_sign_and_local_masks(area_ids, is_inh)\n",
        "\n",
        "    # Model\n",
        "    model = LIFLayerBio(N, S_sign.to(device), Lmask.to(device), Dmask.to(device), dt=dt).to(device)\n",
        "\n",
        "    # t+1 prediction setup\n",
        "    # Δ를 고정하거나 랜덤으로 뽑기\n",
        "    delta = np.random.randint(1, 6)  # 1~5 step 랜덤\n",
        "    inp, tgt = make_inputs_targets_from_binned_shift(X, delta=delta)\n",
        "\n",
        "    # Train\n",
        "    hist = train_tplus1(model, inp, tgt, epochs=50, lr=1e-2, lambda_in=0.0, lambda_w1=lambda_w1_val, verbose=False)\n",
        "\n",
        "    # Robustness\n",
        "    # _ratio, _lo, _lp = robustness_ratio(model, inp, tgt, frac=0.2) # Skipping for now to focus on CCG\n",
        "\n",
        "    # CCG vs W on top-|W| pairs\n",
        "    with torch.no_grad():\n",
        "        W_eff = model.effective_W()\n",
        "    ccg_res = ccg_vs_W_summary(binned_NxT=stitched, W_eff=W_eff, dt=dt, K=2000, max_lag_bins=50, use_abs=True, plot=False)\n",
        "\n",
        "    print(f\"Results for lambda_w1 = {lambda_w1_val}\")\n",
        "    print(f\"CCG asym (0–20ms pos - neg) vs W: r = {ccg_res['r_asym']:.3f}\")\n",
        "    print(f\"CCG pos-lag peak (0–20ms) vs W:  r = {ccg_res['r_pospeak']:.3f}\")\n",
        "    print(\"-\" * 20)\n",
        "\n",
        "# Experiment with different lambda_w1 values\n",
        "lambda_values = [1e-5, 1e-4, 1e-3, 1e-2]\n",
        "\n",
        "for lambda_val in lambda_values:\n",
        "    main_with_lambda(lambda_val)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}